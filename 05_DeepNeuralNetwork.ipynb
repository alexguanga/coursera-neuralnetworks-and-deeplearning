{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep L-layer neural network\n",
    "\n",
    "- Logistic Regression are considered a shallow neural network\n",
    "- Then there are 1 hidden layer which are a 2layer NN\n",
    "- We could have 2 hidden layers\n",
    "- Lastly, we have 5 hidden layers which could be considered a deep neural network\n",
    "\n",
    "Notation: (You can also use the screenshot as a reference)\n",
    "- L = 4 (# of layers)\n",
    "- $n^{[l]}$ = # of units in layers, l\n",
    "    - $n^{[0]}$ = $n_{[x]}$ = 3\n",
    "    - $n^{[1]}$ = 5\n",
    "    - $n^{[2]}$ = 5\n",
    "    - $n^{[3]}$ = 3\n",
    "    - $n^{[4]}$ = $n^{[L]}$ = 4\n",
    "- $a^{[l]}$ = activation in layers, l\n",
    "- $a^{[l]}$ = $g^{[l]}(z^{[l]})$\n",
    "- $W^{[l]}$ & $b^{[l]}$ for $z^{[l]}$\n",
    "\n",
    "- $\\hat{y} = a^{[L]}$\n",
    "\n",
    "<img src=\"./images/deep_68.png\" alt=\"Drawing\" style=\"width: 450px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation in a Deep Network\n",
    "\n",
    "Must remember: Andrew Ng consistently talks about the forward propogation. It is the mechanism that goes through the network. \n",
    "\n",
    "Remember: There's a difference btw the A vector and the W and b vectors.  The A vector begins at 0 which the inputs or X. BUT, the W vector is called $W^{[1]}$\n",
    "\n",
    "Vectorization\n",
    "- $Z^{[1]} = W^{[1]}A^{[0]} + b^{[1]}$\n",
    "- $A^{[1]} = g^{[1]}(Z^{[1]})$\n",
    "- $Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]}$\n",
    "- $A^{[2]} = g^{[2]}(Z^{[2]})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting your matrix dimensions right\n",
    "\n",
    "<img src=\"./images/deep_69.png\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "\n",
    "- Pay attention to the hidden units in each of the layers\n",
    "\n",
    "<img src=\"./images/deep_70.png\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "\n",
    "- Follow the steps:\n",
    "- The X vectors or $A^{[0]}$ is a 2 by 1 Matrix and $n^{[1]}$ is a 3 by 1 matrix.\n",
    "- Thus, by matrix multiplication, our weights must be a 3 by 2 matrix\n",
    "- Moreover, this a ($n^{[1]}, n^{[0]}$) matrix.\n",
    "- This rule could be applied to every layer, and it would work. \n",
    "- Thus for $W^{[l]}: (n^{[l]}, n^{[l-1]})$\n",
    "- Since the bias vector is an addictive operation, we do not have much to change:\n",
    "    - $b^{[l]}: (n^{[l]}, 1)$\n",
    "\n",
    "- Remember, the gradients of the function should be the same as the function:\n",
    "- $dW^{[l]}: (n^{[l]}, n^{[l-1]})$\n",
    "- $db^{[l]}: (n^{[l]}, 1)$\n",
    "\n",
    "The following is an example:\n",
    "- <img src=\"./images/deep_71.png\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "- Also all the training examples are compressed: Meaning that every single of the vector (horizontally) is for a person where each variable is a row. They are transposed!\n",
    "- <img src=\"./images/deep_72.png\" alt=\"Drawing\" style=\"width: 350px;\"/>\n",
    "- Notice how we are changing the 1 to m. Meaning we are not looking at one observation but rather, all the training examples!\n",
    "- $z^{[l]}, a^{[l]}: (n^{[l]}, 1)$\n",
    "- $Z^{[l]}, A^{[l]}: (n^{[l]}, m)$\n",
    "- Special case (when we are layer 0)\n",
    "- layer = 0, $A^{[0]} = X = (n^{[0]}, m)$\n",
    "- $dZ^{[l]}, dA^{[l]}: (n^{[l]}, m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why deep representations?\n",
    "\n",
    "The understanding is that we need to figure out how we can break down a complex thing, like a puzzle, and then normalize it to a correct intrepreation of the data problem.\n",
    "\n",
    "There has been comparision with the brain. We start thinking through small, insignficant concept and then we build a complex understand through these small tasks.\n",
    "\n",
    "Another reason for why deep learning do great\n",
    "- From Circuit theory and deep learning\n",
    "    - Informally: There are functions you can compute with a \"small\" L-layer deep neural network that shallower networks require exponetially more hidden units to compute\n",
    "    - Shallow networks tend to have one hidden network but we would need a lot more hidden nodes in the same layers for what a small L-layer deep neural network would (prob. would not even not need a lot of neural network)\n",
    "    \n",
    "Why is that the case:\n",
    "- Remember when we were learning information theory. One key concept was that we should try to use a decision tree to break down the number of choices rather than compare each choice with each choice. The concept is the same.\n",
    "- with a neural network, we would need Order(Log(n)) options, so if we have 8 differert examples, we would need 3 neural networks. $log_2(8) = 3$\n",
    "- However, if we perform this against all the possibilities would exponentially large, or $2^8$ = 256, since you need to calculate for all possible calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building blocks of deep neural networks\n",
    "Forward Propogation\n",
    "- <img src=\"./images/deep_73.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Backward/Forward Propogation\n",
    "- <img src=\"./images/deep_74.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward and Backward Propagation\n",
    "\n",
    "Forward propogation for layer l\n",
    "- Input $a^{[l-1]}$\n",
    "- Output $a^{[l]}$, cache $(z^{[l]})$\n",
    "\n",
    "Backward propogation for layer l\n",
    "- Input $da^{[l]}$\n",
    "- Output $da^{[l-1]}$, $dW^{[l]}$, $db^{[l]}$\n",
    "\n",
    "One imp thing to know:\n",
    "- For $da^{[l]}$, the derative is $-y/a + ((1-y)/(1-a))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters vs Hyperparameters\n",
    "\n",
    "What are hyperparameters?\n",
    "- Parameters: $W^{[1]}, b^{[1]}, W^{[2]}, b^{[2]}, W^{[3]}, b^{[3]}$\n",
    "- Hyperparamters could be:\n",
    "    - The learning rate alpha $\\alpha$\n",
    "    - Total nums of iterations\n",
    "    - Total nums of hidden layers, L\n",
    "    - Total nums of hidden units, $n^{[1]}, n^{[1]}$\n",
    "    - Choice of activation functions (ReLu)\n",
    "- Other hyper parameters could be:\n",
    "    - Momentium, mini-batch, size, regularization\n",
    "\n",
    "You must play around with the hyperparameters to better understand how they work. \n",
    " \n",
    "The process is very empirical, where we have to find the best hyperparameters through experimentation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this have to do with the brain?\n",
    "\n",
    "- <img src=\"./images/deep_75.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "While the anaology btw a neuron and neuron from a neural network could have similarities, even neuroscientist do not have a concrete idea of what a neuron does\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
