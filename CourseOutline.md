# Neural Networks

1. [Introduction to Deep Learning](https://github.com/alexguanga/coursera-neuralnetworks-and-deeplearning/blob/master/01_IntroductionToDeepLearning.ipynb#supervised-learning-with-neural-networks)
  - What is a Neural Network?
  - Supervised Learning with Neural Networks
  - Why is Deep Learning Taking Off?
  - About This Course
2. [Logistic Regression as a Neural Network](https://github.com/alexguanga/coursera-neuralnetworks-and-deeplearning/commit/7ca8cf4161c07dec33e60972b6f8829190950a60)
  - Binary Classification
  - Logistic Regression
  - Logistic Regression Cost Function
  - Gradient Descent
  - Derivatives
  - More Derivatives Examples
  - Computation Graph
  - Derivatives with Computation Graph
  - Logistic Regression Gradient Descent
  - Gradient Descent on Examples
3. [Python and Vectorization](https://github.com/alexguanga/coursera-neuralnetworks-and-deeplearning/blob/master/03_Python%26Vectorization.ipynb)
  - Vectorization
  - More Vectorization Examples
  - Vectorization Logistic Regression
  - Vectorization Logistic Regression's Gradient Output
  - Broadcasting in Python
  - A Note on Python/Numpy Vectors
  - Explanation of Logistic Regression Cost Function (Optional)
4. [Shallow Networks](https://github.com/alexguanga/coursera-neuralnetworks-and-deeplearning/blob/master/04_ShallowNetwork.ipynb)
  - Neural Network Overview
  - Neural Network Representation
  - Computing a Neural Network's Output
  - Vectorizing Across Multiple Examples
  - Explanation for Vectorized Implementation
  - Activation Functions
  - Why Do You Need Non-linear Activation Functions?
  - Derivatives of Activation Functions
  - Gradient Descent for Neural Networks
  - Back Propagation Intuition (optional)
  - Random Initialization
5. [Deep Neural Networks](https://github.com/alexguanga/coursera-neuralnetworks-and-deeplearning/blob/master/05_DeepNeuralNetwork.ipynb)
  - Deep L-layer Neural Network
  - Forward Propagation in a Deep Network
  - Getting Your Matrix Dimension Right
  - Why Deep Representations?
  - Building Blocks of Deep Neural Networks
  - Forward and Backward Propagation
  - Parameters VS. Hyper-parameters
  - What Does This Have to Do with the Brain?
