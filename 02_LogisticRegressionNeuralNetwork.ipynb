{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression as a Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "<img src=\"./images/deep_11.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "In the image above, the pixels (segmented by their color categories: R,B,G) are transformed into one large vector.\n",
    "\n",
    "- The total number of rows will be calculated by 64 * 64 (representing the height and width of the image) * 3 (the 3 layers) = 12288\n",
    "\n",
    "**m represents the total number of observations (or rows).**\n",
    "\n",
    "**n represents the total number of pixels for per observation (or column)**\n",
    "\n",
    "Then, we will use the rows and vectorize it and then add it one matrix! \n",
    "\n",
    "- One column represents one observation with its pixels values.\n",
    "\n",
    "- <img src=\"./images/deep_12.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "- <img src=\"./images/deep_13.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Overview of logistic regression\n",
    "- <img src=\"./images/deep_14.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "The sigmoid function $1/(1+e^{-value})$ calculates a binary probability (yes or no).\n",
    "\n",
    "The formula is intutive. For example, if $value$ is a large positive number, then the sigmoid function will be a number close to 0. \n",
    "- When $value$ is large, then $e^{-value}$ is close to 0. Hence, the sigmoid function will be $1/(1+0)$ which equals 1.\n",
    "- The intuition is the same when the $value$ is a large negative value. The equation $e^{-value}$ will be a large number since a two negative (one from the actual $value$ and the other from the equation). Hence the sigmoid function will be $1/(1+$large_value$) which equals a small number. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Cost Function\n",
    "\n",
    "The shape of the logistic loss function depends on the ground truth (the actual data label). When we are giving a 0 probaibility but the actual is 1, then the loss function is huge! Same thing the other way!\n",
    "- <img src=\"./images/deep_18.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "<img src=\"./images/deep_15.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "- Noticed that ith is for the training example\n",
    "- you can compute the loss with the MSE, but in logistic regression, you cannot do this bc you have non-convex!\n",
    "\n",
    "<img src=\"./images/deep_16.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "The loss function, described above, is the loss function we use for logistic regression.\n",
    "\n",
    "<img src=\"./images/deep_17.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "If we look at the image above, we see that the our goal is to have as big as possible (since our goal is to have the value to be 1, that is our prediction)! Same concept for when the prediction is 0. We want the y hat, prediction, to be close to 0!\n",
    "\n",
    "The cost function is the overall performance of the entire training set. We adjust based on what we find!\n",
    "- <img src=\"./images/deep_19.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "Concept is faily simply, we are in top of a mountain where we are trying to find the best path to get to the bottom. One great thing with gradient descent in logistic regression is that we will always have a (or most of the time) a convex function. \n",
    "\n",
    "The learning rate is one of the most important things since it finds how large of a step we need to take.\n",
    "\n",
    "In the following code: \n",
    "```python\n",
    "def update_weights(m, b, X, Y, learning_rate):\n",
    "    m_deriv = 0\n",
    "    b_deriv = 0\n",
    "    N = len(X)\n",
    "    for i in range(N):\n",
    "        # Calculate partial derivatives\n",
    "        # -2x(y - (mx + b))\n",
    "        m_deriv += -2*X[i] * (Y[i] - (m*X[i] + b))\n",
    "\n",
    "        # -2(y - (mx + b))\n",
    "        b_deriv += -2*(Y[i] - (m*X[i] + b))\n",
    "\n",
    "    m -= (m_deriv / float(N)) * learning_rate\n",
    "    b -= (b_deriv / float(N)) * learning_rate\n",
    "\n",
    "    return m, b\n",
    "```\n",
    "We update the deritivative (from the code above) by the average. In essence, we are calculating the derivatives of every observations and then calculating the average. As we will see later, there are other methods when calculating how we modify our derivatives.\n",
    "- <img src=\"./images/deep_20.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivatives\n",
    "<img src=\"./images/deep_21.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "Noticed that the nudge is the change or the derviative.\n",
    "\n",
    "For example, in the image above, we are stating that one unit change in the x-axis will lead to three unit change in the y-axis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Derivative Examples\n",
    "<img src=\"./images/deep_22.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "As we see, the derivative is an easy example.\n",
    "\n",
    "<img src=\"./images/deep_23.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "The last example is the most intersting with the logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation graph\n",
    "Make sure that you keep track of how the function are computed one top of another...\n",
    "<img src=\"./images/deep_24.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "The point of the video was to show that we have to compute forward to get the answer. thus, to get the deriatives, we need to compute backwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivatives with a Computation Graph\n",
    "<img src=\"./images/deep_25.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "We see that the first deritative gives us the first nudge. However, we would need to find the nudges from the beginning of the function!\n",
    "\n",
    "In the image below, when we focus on **a** (noticed that a only works on the addition function), we understand that a change of .00001 changes the final function by 3 times that! Since the derivative of **a** is 1.\n",
    "- <img src=\"./images/deep_26.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "Sidenote: dvar will be used in the code to show the last function we are trying to optimize for, in the image above, it would be for the J function\n",
    "\n",
    "The following example could be the most complicated one... look at u=bc. \n",
    "- When we find the deritative of b, \n",
    "    - ...we get c which affects the v=a+u function. \n",
    "    - ...we plut b=2, which calculates to 2 * 3 = 6\n",
    "- Noticed that the $dJ/dU$ is the chain rule of $dJ/dV * dV/dU$, which is 3 hence, the examples of $dJ/dA$ using 3!\n",
    "- <img src=\"./images/deep_27.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Gradient Descent\n",
    "<img src=\"./images/deep_28.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Quick things to keep in mind is the way it computes if we go backward. For the first step, when we retrieve, we find that the result \n",
    "- -(y/a)+(1-y)/(1-a)\n",
    "- Then, when we find the deriative of the a(1-a), and we simplfy it, we get a(1-a)\n",
    "- We then return to the original variables (the weights)\n",
    "<img src=\"./images/deep_29.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent on m Examples\n",
    "Remember, that the previous example shave only been when working with a specific training example. To have the full implementation, we need to find the average of the gradient of all the training examples to find the average gradient descent of our problem. \n",
    "\n",
    "The bad thing is that we  will have to use for loops (back in the day). Now, we are fortunate to use vectorization. Makes the code run quicker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
